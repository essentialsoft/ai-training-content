<!--  Module Title -->
# Introduction to LLM Engineering

**Difficulty** :  Advanced

**Topics** :  AI Frameworks, AI Safety, AI Tools, AI in Software Development, Agents, RAG, Testing, Workflow

<!--  MODULE PAGE METADATA -->

<!-- CONTENT -->

## Module Overview
Learn the engineering that surrounds LLMs in production. This module covers ingestion pipelines, retrieval with vector databases, prompt orchestration, fine-tuning, evaluation, monitoring, and safety. You will design modular systems that are observable, testable, and scalable—aligned to ESI’s AI-powered software development lifecycle across platform, ML, and application teams.

## Learning Objectives
- Design end-to-end LLM architectures that separate ingestion, retrieval, orchestration, inference, and post-processing.
- Implement RAG pipelines and efficient fine-tuning (e.g., LoRA/QLoRA) with versioned data and model artifacts.
- Evaluate LLM applications using heuristics, similarity metrics, and LLM-as-judge techniques; build reproducible evaluation datasets.
- Instrument logging, tracing, and monitoring to analyze latency, token usage, drift, and safety events in production.
- Troubleshoot retrieval quality, prompt brittleness, and failure modes using adversarial testing and guardrails.

## Start the Course
### LLM Engineering: Master AI, Large Language Models & Agents
**Instructor**: Ligency; Ed Donner  
**Duration**: 25.5 hours  
**Last Updated**: Not stated

Hands-on program that builds eight production-grade LLM apps using RAG, QLoRA fine-tuning, and agentic workflows. Learners practice data ingestion, vector databases, and deployment patterns while comparing open-source and frontier models. By the end, developers can ship reliable LLM features with monitoring, guardrails, and modular pipelines aligned to enterprise delivery.

Access course via [Udemy]({{https://www.udemy.com/course/llm-engineering-master-ai-and-large-language-models/?utm_source=chatgpt.com&couponCode=PMNVD1525}})  

### Engineering Practices for LLM Application Development
**Instructor**: David Tan, Lead ML Engineer @ Thoughtworks; Jessie Wang, Senior Data Scientist @ Thoughtworks  
**Duration**: self-paced  
**Last Updated**: February 13, 2024

Field guide from Thoughtworks engineers on shipping LLM applications responsibly. It covers example-based tests, LLM auto-evaluators, and adversarial prompts; prompt refactoring; and ethical guidelines. Readers learn practical architecture and delivery patterns that reduce regressions, improve safety, and keep iteration speed high—ideal for teams integrating LLMs into existing software systems.

Access course via [Martin Fowler]({{https://martinfowler.com/articles/engineering-practices-llm.html}})  